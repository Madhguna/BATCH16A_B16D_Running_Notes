
1. What Docker & Docker Compose Do Well ???

Docker helps you:

      Package your app and dependencies into portable containers.      
      Run the same container anywhere (dev, test, prod).      
      Isolate processes and environments.
      
Docker Compose adds:

    Multi-container setup — e.g., running a web app + DB + Redis + xyz ..etc  together.    
    Simple configuration — define everything in docker-compose.yml.    
    Great for local development and small deployments.
    
So far, so good , we can 

    Package apps consistently (Dockerfile) 
    Define multiple containers easily (docker-compose.yml)
    Run them locally with one command
    Even auto-restart containers with restart: always



CHALLENGES WITH DOCKER &  DOCKER COMPOSE 
========================

1 Scaling and High Availability

     Docker Compose doesn’t automatically scale containers across multiple machines.     
     If one container/node fails, you need to manually restart or handle failover.     
     No built-in load balancing or auto-recovery.

2 Multi-host / Cluster Management
      Docker Compose works mostly on a single host (machine)
      Real production systems need to run across multiple servers or clouds — Compose doesn’t handle that.

3. Self-healing & Monitoring
      If a container crashes, Compose won’t automatically reschedule or replace it.   
      You need to handle health checks and restarts manually.

4. Rolling Updates / Zero-downtime Deployments

      Docker Compose lacks advanced deployment strategies (rolling updates, blue-green, canary, etc.).

5. Networking & Service Discovery

      Compose’s network works fine locally, but in a distributed environment you need dynamic service discovery, DNS, and load balancing — which Compose doesn’t provide natively.
	  
6. Resource Management

     You can set limits, but no cluster-level scheduling based on CPU/RAM usage	 
	 
7.  Monitoring and logging need extra tools	 
	 


- DOCKER CAN NOT ORCHESTRATE

==============================================
DOCKER 

CONT.ORC CONCEPTS ---> DOCKER SWARM / K8S 


-------------------------------------------------------
WHY KUBERNETES (K8S):
=========================
- Production-grade scaling
- High Availability 
- Self-healing: 
- Automated rollouts , rollback & zero downtime
- Automates container orchestration & Automated Scheduling (hpa) 
- Scales containers up or down easily
- Handles networking across clusters
- Built-in load balancing
- Simplifies deployment and updates



========================================================================
What is Kubernetes?
•	Kubernetes is an orchestration engine and open-source platform for managing containerized applications.
•	Born in Google ,written in Go/Golang. Donated to CNCF(Cloud native computing foundation) in 2014.
•	Kubernetes v1.0 was released on July 21, 2015.


FEATURES:

•	Automated Scheduling: 
Kubernetes provides advanced scheduler to launch container on cluster nodes based on their resource
requirements and other constraints, while not sacrificing availability.

•	Self Healing Capabilities:
 Kubernetes allows to replaces and reschedules containers when nodes die. It also kills containers that don’t
respond to user-defined health check and doesn’t advertise them to clients until they are ready to serve.

•	Automated rollouts & rollback: 
Kubernetes rolls out changes to the application or its configuration while monitoring application health
to ensure it doesn’t kill all your instances at the same time. If something goes wrong, with Kubernetes you can rollback the change.

•	Horizontal Scaling & Load Balancing:
 Kubernetes can scale up and scale down the application as per the requirements with a simple
command, using a UI, or automatically based on CPU usage.

=================================================================================


SOFTWARES:  eksctl , kubectl , aws cli , visual studo code (ide) 

MINIKUBE , KIND 


aws  - EKS 
azure - AKS
gcp - GKE

1. chacolety 
--------------------------------------
2. eksctl -- CLUSTER CREATION 
 eksctl version
0.215.0

--------------------------------------

3. kubectl -- CLI TO INTERACT WITH CLUSTER ( API SERVER) 
 kubectl version --client
Client Version: v1.34.1-eks-113cf36
Kustomize Version: v5.7.1

--------------------------------------
4. AWS CLI 
 aws --version
aws-cli/2.23.9 Python/3.12.6 Windows/11 exe/AMD64

ACCESS KEY 
SECRET ACCESS KEY 

-----------------------------------------

5. visual studio code  (IDE ) 
   - For syntax auto suggestions / syntax auto completion 
   - easy to manage the code / script 

============================

Installing on linux machine :: 

kubectl & eksctl installation on aws linux machine 

curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"


curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"


sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl


============================================================


WHY K8S 

High availability , Zero downtime , 

K8S ARCHITECTURE:
================

Kubernetes Architecture is based on a master-worker model, where the Master manages and controls the cluster, and the Workers run the containerized applications. Let's break down the architecture and its core components.

KUBERNETES ARCHITECTURE :

Master Node:    The control plane responsible for managing the Kubernetes cluster.
Worker Nodes:   The nodes that run the containerized applications (pods).
Cluster:        A set of worker nodes managed by the master node.


---------------------------------------

1. MASTER NODE (CONTROL PLANE): 
============================
The Master Node is the brain of the Kubernetes cluster. 
It manages the cluster, maintains the desired state, schedules workloads, and monitors the overall health of the cluster.
It consists of several critical components:

     KUBE-APISERVER:     
     The API server is the central point of contact for all Kubernetes components. It handles requests from clients, whether that’s the kubectl CLI, the Kubernetes UI, or other components in the system.     
     The API server exposes the REST API, which is used by external clients to interact with Kubernetes. It ensures the system’s state is updated.
	 
    -  The entry point /Gateway to the Kubernetes cluster.
    -  All commands (like kubectl) talk to the API server.
    -  Think of it as the front desk of K8s.
	   
	 
	 
     ETCD:     
 
	- A key-value database that stores all cluster data — pods, deployments, secrets, etc.
	- It is highly available and persistent - Kubernetes can recover the cluster's state even after a failure.
	- etcd ensures consistency across the entire cluster.
    - It’s like Kubernetes’ memory.
     
	 
     KUBE-SCHEDULER:     
     
	- Watches for new pods that need to be scheduled.
    - Decides which node a pod should run on (based on resources, affinity rules, etc)  
    - ensures that workloads are distributed across nodes in an efficient and optimal manner.
     
     
	 KUBE-CONTROLLER-MANAGER:     
	 
	- Runs various controllers (like replica controller, node controller, etc.) 
    - Ensure that the cluster's desired state is maintained. (desired state = actual state) 
    - Ex: if you said you want 3 replicas but only 2 are running, it creates 1 more. 

     
     CLOUD-CONTROLLER-MANAGER (OPTIONAL):     
	 
    - This component is used when running Kubernetes in a cloud environment. 
	- Interacts with the underlying cloud provider (e.g., AWS, AZURE , Google Cloud) to manage resources like    load balancers, volumes, and instances.
	- It helps in maintaining cloud-specific services in coordination with Kubernetes.
     
	 
2. WORKER NODE COMPONENTS:
===========================

     A Worker Node (also called a Minion) runs the applications and workloads in the form of Pods. Each worker node contains the following components:
     
     KUBELET:     
	 
	- The agent on each worker node that talks to the API Server.
	-  Makes sure containers are running as instructed.
	- takes action to rectify any issues (e.g., restarting a failed container).
	
     
	 
     KUBE-PROXY:     
	 
	- Handles networking — ensures pods can talk to each other and the internet.
	- Manages load balancing and routing traffic to the right pod.     
	
     
     CONTAINER RUNTIME (DOCKER/ cri-o / containerd)  

    - Runs the containers inside a pod (Docker, containerd, CRI-O, etc).
    - It pulls container images, starts containers, and manages the lifecycle of containers within the pods.
	 
======================================     
     PODS:     
	 
	- Pod : The Smallest Deployable Unit in K8S
    - Pod is the basic building block in Kubernetes.
	- It wraps one or more containers that share the same network and storage.
	- Usually, one container per pod (but sometimes more if they’re tightly coupled).
	 

So who actually makes the pod run ? 
   
   
   API Server - Accepts pod creation requests, validates and stores them in etcd 
   Scheduler - Watches for unscheduled pods, selects a node - Decides which node should host the pod
   API Server - Updates Pod with node assignment     
   Kubelet	-  on the chosen node , talks to Container Runtime to  create containers, 
   
   
 So kubelet Actually runs and monitors the pod on its node, kubelet reports status back to API SERVER 

=============================================================================================


Where can you set up a Kubernetes cluster?

1. Self-managed cluster - You install and manage everything yourself.
    Treditional approach - Self managed , barematel , customer managed k8s cluster 
    Kubeadm → install K8s manually on servers (on-prem or in the cloud).
	
	
  Kubernetes Control Plane - Self Managed  
        Need to make Control Plane Highly Available
        Maintain multiple EC2 in multiple AZ
        Scale Control Plane if needed
        Keep etcd up and running
        Overhead of managing EC2s
        Security Patching
        Replace failed EC2s/vms/physical servers
        Orchestration for Kubernetes Version Upgrade

2. Managed Kubernetes services (cloud)
    
	 k8s cluster as a service , Cloud providers give you a ready-to-use Kubernetes control plane.
     You just focus on your apps, not managing Kubernetes itself.

         AWS	   EKS (Elastic Kubernetes Service)
         GCP      GKE (Google Kubernetes Engine)
         Azure	   AKS (Azure Kubernetes Service)



   
   CLOUD MANAGED KUBERNETES ( EKS / AKS / GKE ) 

       Kubernetes Control Plane - AWS Managed - eks
       
       ● AWS Manages Kubernetes Control Plane 
       ● Creates and manages the Control Plane for you (API server, etcd, scheduler, etc.)
       ● Handles upgrades, scaling, and security patches automatically.
       ● AWS maintains High Availability - Multiple EC2s in Multiple AZs
       ● AWS Detects and Replaces Unhealthy Control Plane Instances
       ● AWS Scales Control Plane
       ● Provides Automated Version Upgrade and Patching


   in EKS you only need to manage Data Plane 

   ● Create Worker Nodes (EC2 instances or Fargate tasks)   - we will use managed node groups 
   ● Deploy our  Pods and apps.
   ● Cluster configuration
   ● Security policies
   ● Monitoring/logging
   
   
   

EKS K8S CLUSTER SETUP 


====================================================

Ways To Spin Up EKS Cluster:

           
           eksctl CLI
		   
		   
          
What is eksctl - CloudFormation stack
  

     ● CLI tool for creating clusters on EKS
     ● Easier than console
     ● Abstracts lots of stuff - VPC, Subnet, Sec. Group , nodes , docker etc.
     using CloudFormation stack 

=======================	   
aws configure

Accesskey 
Secret Access key 
---
AKIASB5MXXXXXXXXXXXXXXXXXXXXX
DSR3tgUbjV1KgwglXXXXXXXXXXXXXXX

1. awscli & configufre 
aws sts get-caller-identity

once configure is done , our terminal will have admin accss to our aws account 


=======================================================
eksctl create cluster  

--> it creates  two m5.large large nodes by default for data plane . Insted go for t3.micro

  
     Control Plane - AWS WILL TAKE CARE !   
     Data Plane  - 2 m5.large worker nodes 


eksctl create cluster --name <name> --version <> --nodegroup-name <> --node-type t3.micro --nodes 4 --managed 



eksctl create cluster --name b16dcluster  --nodegroup-name b16ng --node-type t3.micro --nodes 4 --managed 

=======================================================


eksctl get cluster 
eksctl delete cluster <clustername> 
=============================================================


2024-11-07 19:03:13 [ℹ]  waiting for CloudFormation stack "eksctl-b15cluster-cluster"
:
:
2024-11-07 19:34:33 [ℹ]  waiting for CloudFormation stack "eksctl-b15cluster-nodegroup-b15ng"
:
:
2024-11-07 19:37:57 [ℹ]  nodegroup "b15ng" has 4 node(s)
2024-11-07 19:37:57 [ℹ]  node "ip-192-168-1-245.ec2.internal" is ready
2024-11-07 19:37:57 [ℹ]  node "ip-192-168-30-5.ec2.internal" is ready
2024-11-07 19:37:57 [ℹ]  node "ip-192-168-48-160.ec2.internal" is ready
2024-11-07 19:37:57 [ℹ]  node "ip-192-168-52-207.ec2.internal" is ready
2024-11-07 19:37:57 [✔]  created 1 managed nodegroup(s) in cluster "b15cluster"
2024-11-07 19:38:01 [ℹ]  kubectl command should work with "C:\\Users\\Dell\\.kube\\config", try 'kubectl get nodes'
2024-11-07 19:38:01 [✔]  EKS cluster "b15cluster" in "us-east-1" region is ready


-------------------------------------------------------------
CONTROL PLANE (MASTER NODES) :

Kubernetes master nodes are distributed across several AWS availability zones (AZ), and traffic is managed by Elastic Load Balancer (ELB).

EKS is a managed service, so you have no direct access to the master nodes. And you don't need the access.
==================================

pod - Containers are encapsulated into a k8s object called pod ,in simple words pod is a abstraction on containers 

Pod can have multiple continers but in general not of same container type (mostly helper container) 	

--------------------------------------------
Creating a POD from Commandline : 


docker run --name cot1 image
kubectl run testpod --image=tomcat 


history:

 eksctl create cluster --name testcluster  --nodegroup-name testng --node-type t3.micro --nodes 5 --managed
 eksctl get cluster
 kubectl get nodes
 kubectl run testpod --image tomcat
 kubectl get pods
 kubectl describe pod testpod
 kubectl run pd2 --image tomicaaaat
 kubectl get pods
 kubectl describe pod pd2
 kubectl get pods
 kubectl run pod3 --image amazonlinux
 kubectl get pods
 kubectl get pods
 kubectl describe pod pod3
 eksctl get cluster
 eksctl delete cluster testcluster


DISCUSSED : 
IMAGE PULL BACKOFF 
CRASHLOOP BACK OFF ERROR 

